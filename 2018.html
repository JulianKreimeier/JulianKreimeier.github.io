<section>
    <div class="container">

        <hr>
        <h4 id="2018">2018</h4>
        <hr>

        <div class="row">
            <div class="col-lg-4 col-md-4 col-sm-12 text-center">
                <img style="padding: 5%" width="100%"
                     src="assets/img/FeelVR.png">
            </div>
            <div class="col-lg-8 col-md-8 col-sm-12" style="padding:2%">
                <span class="papertitle">FeelVR: Haptic Exploration of Virtual Objects</span>
                <br>
                J. Kreimeier<span style="font-weight: lighter"> and T. Goetzelmann</span>
                <br>
                <em>International Conference on PErvasive Technologies Related to Assistive Environments </em>2018
                <br>
                <p class="d-inline-flex gap-1">
                    <a class="btn btn-dark" data-bs-toggle="collapse" href="#collapseFeelVR" role="button"
                       aria-expanded="false" aria-controls="collapseFeelVR">
                        Abstract
                    </a>
                    <a class="btn btn-dark"
                       href="https://dl.acm.org/doi/abs/10.1145/3197768.3201526">ACM</a>
                </p>
                <div class="collapse" id="collapseFeelVR">
                    <div class="card card-body">
                        <p>
                            The interest in virtual and augmented reality increased rapidly in the last years. Recently, haptic interaction and its applications get into focus. In this paper, we suggest the exploration of virtual objects using off-the-shelf VR game controllers. These are held like a pen with both hands and were used to palpate and identify the virtual object. Our study largely coincides with comparable previous work and shows that a ready-to-use VR system can be basically used for haptic exploration. The results indicate that virtual objects are more effectively recognized with closed eyes than with open eyes. In both cases, objects with a bigger morphological difference were identified the most frequently. The limitations due to quality and quantity of tactile feedback should be tackled in future studies that utilize currently developed wearable haptic devices and haptic rendering involving all fingers or even both hands. Thus, objects could be identifiable more intuitively and haptic feedback devices for interacting with virtual objects will be further disseminated.
                        </p>
                    </div>
                </div>
            </div>
        </div>
        <br>
        <div class="row">
            <div class="col-lg-4 col-md-4 col-sm-12 text-center">
                <img style="padding: 5%" width="100%"
                     src="assets/img/Capacitive.png">
            </div>
            <div class="col-lg-8 col-md-8 col-sm-12" style="padding:2%">
                <span class="papertitle">Evaluation of Capacitive Markers Fabricated by 3D Printing, Laser Cutting and Prototyping</span>
                <br>
                J. Kreimeier<span style="font-weight: lighter">T. Bielmeier, and T. Goetzelmann</span>
                <br>
                <em>Inventions </em>2018
                <br>
                <p class="d-inline-flex gap-1">
                    <a class="btn btn-dark" data-bs-toggle="collapse" href="#collapseCapacitive" role="button"
                       aria-expanded="false" aria-controls="collapseCapacitive">
                        Abstract
                    </a>
                    <a class="btn btn-dark"
                       href="https://www.mdpi.com/2411-5134/3/1/9">MDPI</a>
                </p>
                <div class="collapse" id="collapseCapacitive">
                    <div class="card card-body">
                        <p>
                            With Tangible User Interfaces, the computer user is able to interact in a fundamentally different and more intuitive way than with usual 2D displays. By grasping real physical objects, information can also be conveyed haptically, i.e., the user not only sees information on a 2D display, but can also grasp physical representations. To recognize such objects (“tangibles”) it is skillful to use capacitive sensing, as it happens in most touch screens. Thus, real objects can be located and identified by the touch screen display automatically. Recent work already addressed such capacitive markers, but focused on their coding scheme and automated fabrication by 3D printing. This paper goes beyond the fabrication by 3D printers and, for the first time, applies the concept of capacitive codes to laser cutting and another immediate prototyping approach using modeling clay. Beside the evaluation of additional properties, we adapt recent research results regarding the optimized detection of tangible objects on capacitive screens. As a result of our comprehensive study, the detection performance is affected by the type of capacitive signal processing (respectively the device) and the geometry of the marker. 3D printing revealed to be the most reliable technique, though laser cutting and immediate prototyping of markers showed promising results. Based on our findings, we discuss individual strengths of each capacitive marker type.
                        </p>
                    </div>
                </div>
            </div>
        </div>
        <br>
        <div class="row">
            <div class="col-lg-4 col-md-4 col-sm-12 text-center">
                <img style="padding: 5%" width="100%"
                     src="assets/img/RealWorld.png">
            </div>
            <div class="col-lg-8 col-md-8 col-sm-12" style="padding:2%">
                <span class="papertitle">Real World VR Proxies to Support Blind People in Mobility Training</span>
                <br>
                J. Kreimeier<span style="font-weight: lighter"> and T. Goetzelmann</span>
                <br>
                <em>Mensch und Computer - Workshopband </em>2018
                <br>
                <p class="d-inline-flex gap-1">
                    <a class="btn btn-dark" data-bs-toggle="collapse" href="#collapseRealWorld" role="button"
                       aria-expanded="false" aria-controls="collapseRealWorld">
                        Abstract
                    </a>
                    <a class="btn btn-dark"
                       href="https://dl.gi.de/items/dc39bb6c-af75-4369-a71f-1ba3ca5fb42b">GI</a>
                </p>
                <div class="collapse" id="collapseRealWorld">
                    <div class="card card-body">
                        <p>
                            Mobility training is an essential part of blind people’s education in order to move in public spaces. In order to safely learn new routes in public space, however, a seeing trainer must assist the blind person. With the increasing availability of VR hardware, it is possible to transfer real spatial environments to virtual representations. The digitized environments can be used as a basis for this training without safety problems by real world hazards. This allows to cope with the limited resources of sighted assistants and enables blind people to become more independent. We propose to capture real public spaces (such as sidewalks, train stations etc.) and make them in this way ascertainable. Orientation and mobility can be trained in this digital model via multimodal sensory feedback while involving intuitive locomotion and white cane exploration. This paper sketches the related work and proposes our novel approach. Furthermore, we suggest additional improvements on our ongoing research.
                        </p>
                    </div>
                </div>
            </div>
        </div>
        <br>

    </div>
</section>