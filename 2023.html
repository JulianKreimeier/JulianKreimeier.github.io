<section>
    <div class="container">

        <hr>
        <h4 id="2023">2023</h4>
        <hr>


        <div class="row">
            <div class="col-lg-4 col-md-4 col-sm-12 text-center">
                <img width="100%" src="assets/img/injured.png">
            </div>
            <div class="col-lg-8 col-md-8 col-sm-12">
                <span class="papertitle">Injured Avatars: The Impact of Embodied Anatomies and Virtual Injuries on Well-being and Performance</span>

                <br>
                <span style="font-weight: lighter">C. Kleinbeck, H. Schieber, </span>J. Kreimeier <span style="font-weight: lighter">
                    , A. Martin-Gomez, M. Unberath, and D. Roth
                </span><br>
                <em>IEEE Transactions on Visualization and Computer Graphics</em>, 2023
                <br>
                <p class="d-inline-flex gap-1">
                    <a class="btn btn-dark" data-bs-toggle="collapse" href="#collapseInjury" role="button" aria-expanded="false" aria-controls="collapseInjury">
                        Abstract
                    </a>
                    <a class="btn btn-dark" href="https://ieeexplore.ieee.org/abstract/document/10269734">
                        IEEE
                        TVCG
                    </a>
                </p>
                <div class="collapse" id="collapseInjury">
                    <div class="card card-body">
                        <p>
                            Human cognition relies on embodiment as a fundamental mechanism. Virtual avatars allow
                            users to experience the adaptation, control, and perceptual illusion of alternative
                            bodies. Although virtual bodies have medical applications in motor rehabilitation and
                            therapeutic interventions, their potential for learning anatomy and medical
                            communication remains underexplored. For learners and patients, anatomy, procedures, and
                            medical imaging can be abstract and difficult to grasp. Experiencing anatomies,
                            injuries, and treatments virtually through one's own body could be a valuable tool for
                            fostering understanding. This work investigates the impact of avatars displaying anatomy
                            and injuries suitable for such medical simulations. We ran a user study utilizing a
                            skeleton avatar and virtual injuries, comparing to a healthy human avatar as a baseline.
                            We evaluate the influence on embodiment, well-being, and presence with self-report
                            questionnaires, as well as motor performance via an arm movement task. Our results show
                            that while both anatomical representation and injuries increase feelings of eeriness,
                            there are no negative effects on embodiment, well-being, presence, or motor performance.
                            These findings suggest that virtual representations of anatomy and injuries are suitable
                            for medical visualizations targeting learning or communication without significantly
                            affecting users' mental state or physical control within the simulation.
                        </p>
                    </div>
                </div>
            </div>
        </div>
        <br>
        <div class="row">
            <div class="col-lg-4 col-md-4 col-sm-12 text-center">
                <img width="100%" src="assets/img/EcoEmbodimentPoster.png">
            </div>
            <div class="col-lg-8 col-md-8 col-sm-12">
                <span class="papertitle">Towards Eco-Embodiment: Virtual Reality for Building Climate Change Awareness within Education for Sustainable Development</span>

                <br>
                J. Kreimeier<span style="font-weight: lighter">, L. Theelke, J. Denzler, F. Enders, S. Kumar, and D. Roth</span>
                <br>
                <em>IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)</em>, 2023
                <br>
                <p class="d-inline-flex gap-1">
                    <a class="btn btn-dark" data-bs-toggle="collapse" href="#collapseInjury" role="button" aria-expanded="false" aria-controls="collapseInjury">
                        Abstract
                    </a>
                    <a class="btn btn-dark" href="https://ieeexplore.ieee.org/abstract/document/10322182">
                        IEEE
                    </a>
                </p>
                <div class="collapse" id="collapseInjury">
                    <div class="card card-body">
                        <p>
                            To foster the understanding of the consequences of one’s actions on climate change, low-threshold accessible and understandable content is needed. Virtual Reality (VR) has emerged as a valuable tool in the field of sustainable development education. However, there remains a lack of practical approaches and empirical insights into fostering climate change awareness through an eco-embodiment perspective. Our prototype addresses this gap by immersing users in a VR experience that simulates an everyday life scenario. The player’s activities are calculated as if the entire population of Earth would exhibit such a behavior. At the end of the simulation, they are presented with the long-term scaled global consequences for the environment. Our preliminary evaluation demonstrates the effectiveness of this communication method but also reveals necessary gameplay optimizations toward longitudinal pre/post studies to quantify users’ learning and behavioral changes.
                        </p>
                    </div>
                </div>
            </div>
        </div>
        <br>
        <div class="row">
            <div class="col-lg-4 col-md-4 col-sm-12 text-center">
                <img width="100%" src="assets/img/ICUSimulation.png">
            </div>
            <div class="col-lg-8 col-md-8 col-sm-12">
                <span class="papertitle">Investigating the Effects of Selective Information Presentation in Intensive Care Units Using Virtual Reality</span>

                <br>
                <span style="font-weight: lighter">L. Theelke, F. Metzler, </span>J. Kreimeier<span style="font-weight: lighter">, C. Hauer, J. Binder, and D. Roth</span>
                <br>
                <em>IEEE International Symposium on Mixed and Augmented Reality (ISMAR)</em>, 2023
                <br>
                <p class="d-inline-flex gap-1">
                    <a class="btn btn-dark" data-bs-toggle="collapse" href="#collapseInjury" role="button" aria-expanded="false" aria-controls="collapseInjury">
                        Abstract
                    </a>
                    <a class="btn btn-dark" href="https://ieeexplore.ieee.org/abstract/document/10316439">
                        IEEE
                    </a>
                </p>
                <div class="collapse" id="collapseInjury">
                    <div class="card card-body">
                        <p>
                            Medical personnel working in intensive care units (ICUs) are continuously exposed to a multitude of alarms emanating from various monitoring devices, such as cardiac monitors, ventilators, or infusion pumps. The sheer volume of alarms, coupled with high false positive rates, can lead to alarm fatigue. This phenomenon compromises patient safety and places an additional burden on nurses who must diligently prioritize and respond to alarms in the highly dynamic environment. While the testing of stress-reducing strategies in a real ICU is challenging, virtual reality (VR) represents a powerful tool and methodology to simulate an ICU environment and test optimization scenarios for alarm display strategies. For example, redistributing alarms to responsible individuals (personalized information presentation) has been proposed as a solution, but testing in real ICU environments is not applicable due to critical patient safety. In this paper, we present a VR simulation of an ICU to simulate comparable stress situations, as well as to assess the impact of a selective and personalized alarm representation strategy in an evaluation study in two conditions. A stress condition mirrors the current ubiquitous audible alarm distribution in most ICUs, where alarms are heard non-patient-specific throughout the ward. In an experimental condition, alarms are filtered patient-specific to reduce information overload and noise pollution. Our user study with medical personnel and novices shows that stress levels can be simulated with our system as indicated by physiological responses. Further, we show that the perceived task load can be reduced with selective information presentation. We discuss the potential benefits of ICU simulations as a methodology and personalized alarm distribution as a first potential strategy for future technologies in ICUs.
                        </p>
                    </div>
                </div>
            </div>
        </div>
        <br>
        <div class="row">
            <div class="col-lg-4 col-md-4 col-sm-12 text-center">
                <img width="100%" src="assets/img/Tangibles.png">
            </div>
            <div class="col-lg-8 col-md-8 col-sm-12">
                <span class="papertitle">Adaptive Volumetric Anatomy Visualization in VR with Tangible Control</span>

                <br>
                <span style="font-weight: lighter">C. Kleinbeck, M. Smietana, N. Lewis, T. Teufel, </span>J. Kreimeier <span style="font-weight: lighter">, C. Heinzl, J. Steiner, C. Anthes, and D. Roth</span>
                <br>
                <em>IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)</em>, 2023
                <br>
                <p class="d-inline-flex gap-1">
                    <a class="btn btn-dark" data-bs-toggle="collapse" href="#collapseInjury" role="button" aria-expanded="false" aria-controls="collapseInjury">
                        Abstract
                    </a>
                    <a class="btn btn-dark" href="https://ieeexplore.ieee.org/abstract/document/10316439">
                        IEEE
                    </a>
                </p>
                <div class="collapse" id="collapseInjury">
                    <div class="card card-body">
                        <p>
                            High-quality visualization of medical image data is essential for preoperative planning of complex and critical surgical procedures. Controllable 3D volume rendering in virtual reality (VR) is particularly useful to display depth and spatial relationships in volumetric data, and thus to identify specific anatomical landmarks and structural dependencies. However, intuitive control over the medical volume itself, the selection of sectional planes, transfer functions or the rotation or zooming has yet to be explored in depth. In this work, we demonstrate a real-time VR direct volume rendering application for medical images with tangible and intuitive interaction. Our system is real-time capable by the use of efficient volume rendering and foveated rendering techniques. We evaluated the system regarding its performance and gained first insight into the usefulness of a freely grabbable section slice in a preliminary user study.
                        </p>
                    </div>
                </div>
            </div>
        </div>

    </div>
</section>