<section>
    <div class="container">

        <hr>
        <h4 id="2023">2023</h4>
        <hr>


        <div class="row">
            <div class="col-lg-4 col-md-4 col-sm-12 text-center">
                <img width="100%" src="assets/img/injured.png">
            </div>
            <div class="col-lg-8 col-md-8 col-sm-12">
                <span class="papertitle">Injured Avatars: The Impact of Embodied Anatomies and Virtual Injuries on Well-being and Performance</span>

                <br>
                <span style="font-weight: lighter">C. Kleinbeck, H. Schieber, </span>J. Kreimeier<span style="font-weight: lighter">
                    , A. Martin-Gomez, M. Unberath, and D. Roth
                </span><br>
                <em>IEEE Transactions on Visualization and Computer Graphics</em>, 2023
                <br>
                <p class="d-inline-flex gap-1">
                    <a class="btn btn-dark" data-bs-toggle="collapse" href="#collapseInjury" role="button" aria-expanded="false" aria-controls="collapseInjury">
                        Abstract
                    </a>
                    <a class="btn btn-dark" href="https://ieeexplore.ieee.org/abstract/document/10269734">
                        IEEE
                        TVCG
                    </a>
                </p>
                <div class="collapse" id="collapseInjury">
                    <div class="card card-body">
                        <p>
                            Human cognition relies on embodiment as a fundamental mechanism. Virtual avatars allow
                            users to experience the adaptation, control, and perceptual illusion of alternative
                            bodies. Although virtual bodies have medical applications in motor rehabilitation and
                            therapeutic interventions, their potential for learning anatomy and medical
                            communication remains underexplored. For learners and patients, anatomy, procedures, and
                            medical imaging can be abstract and difficult to grasp. Experiencing anatomies,
                            injuries, and treatments virtually through one's own body could be a valuable tool for
                            fostering understanding. This work investigates the impact of avatars displaying anatomy
                            and injuries suitable for such medical simulations. We ran a user study utilizing a
                            skeleton avatar and virtual injuries, comparing to a healthy human avatar as a baseline.
                            We evaluate the influence on embodiment, well-being, and presence with self-report
                            questionnaires, as well as motor performance via an arm movement task. Our results show
                            that while both anatomical representation and injuries increase feelings of eeriness,
                            there are no negative effects on embodiment, well-being, presence, or motor performance.
                            These findings suggest that virtual representations of anatomy and injuries are suitable
                            for medical visualizations targeting learning or communication without significantly
                            affecting users' mental state or physical control within the simulation.
                        </p>
                    </div>
                </div>
            </div>
        </div>
        <br>
        <div class="row">
            <div class="col-lg-4 col-md-4 col-sm-12 text-center">
                <img width="100%" src="assets/img/EcoEmbodimentPoster.png">
            </div>
            <div class="col-lg-8 col-md-8 col-sm-12">
                <span class="papertitle">Towards Eco-Embodiment: Virtual Reality for Building Climate Change Awareness within Education for Sustainable Development</span>

                <br>
                J. Kreimeier<span style="font-weight: lighter">, L. Theelke, J. Denzler, F. Enders, S. Kumar, and D. Roth</span>
                <br>
                <em>International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)</em>, 2023
                <br>
                <p class="d-inline-flex gap-1">
                    <a class="btn btn-dark" data-bs-toggle="collapse" href="#collapseEcoEmbodimentPoster" role="button" aria-expanded="false" aria-controls="collapseEcoEmbodimentPoster">
                        Abstract
                    </a>
                    <a class="btn btn-dark" href="https://ieeexplore.ieee.org/abstract/document/10322182">
                        IEEE
                    </a>
                </p>
                <div class="collapse" id="collapseEcoEmbodimentPoster">
                    <div class="card card-body">
                        <p>
                            To foster the understanding of the consequences of one’s actions on climate change, low-threshold accessible and understandable content is needed. Virtual Reality (VR) has emerged as a valuable tool in the field of sustainable development education. However, there remains a lack of practical approaches and empirical insights into fostering climate change awareness through an eco-embodiment perspective. Our prototype addresses this gap by immersing users in a VR experience that simulates an everyday life scenario. The player’s activities are calculated as if the entire population of Earth would exhibit such a behavior. At the end of the simulation, they are presented with the long-term scaled global consequences for the environment. Our preliminary evaluation demonstrates the effectiveness of this communication method but also reveals necessary gameplay optimizations toward longitudinal pre/post studies to quantify users’ learning and behavioral changes.
                        </p>
                    </div>
                </div>
            </div>
        </div>
        <br>
        <div class="row">
            <div class="col-lg-4 col-md-4 col-sm-12 text-center">
                <img width="100%" src="assets/img/ICUSimulation.png">
            </div>
            <div class="col-lg-8 col-md-8 col-sm-12">
                <span class="papertitle">Investigating the Effects of Selective Information Presentation in Intensive Care Units Using Virtual Reality</span>

                <br>
                <span style="font-weight: lighter">L. Theelke, F. Metzler, </span>J. Kreimeier<span style="font-weight: lighter">, C. Hauer, J. Binder, and D. Roth</span>
                <br>
                <em>International Symposium on Mixed and Augmented Reality (ISMAR)</em>, 2023
                <br>
                <p class="d-inline-flex gap-1">
                    <a class="btn btn-dark" data-bs-toggle="collapse" href="#collapseICUSimulation" role="button" aria-expanded="false" aria-controls="collapseICUSimulation">
                        Abstract
                    </a>
                    <a class="btn btn-dark" href="https://ieeexplore.ieee.org/abstract/document/10316439">
                        IEEE
                    </a>
                </p>
                <div class="collapse" id="collapseICUSimulation">
                    <div class="card card-body">
                        <p>
                            Medical personnel working in intensive care units (ICUs) are continuously exposed to a multitude of alarms emanating from various monitoring devices, such as cardiac monitors, ventilators, or infusion pumps. The sheer volume of alarms, coupled with high false positive rates, can lead to alarm fatigue. This phenomenon compromises patient safety and places an additional burden on nurses who must diligently prioritize and respond to alarms in the highly dynamic environment. While the testing of stress-reducing strategies in a real ICU is challenging, virtual reality (VR) represents a powerful tool and methodology to simulate an ICU environment and test optimization scenarios for alarm display strategies. For example, redistributing alarms to responsible individuals (personalized information presentation) has been proposed as a solution, but testing in real ICU environments is not applicable due to critical patient safety. In this paper, we present a VR simulation of an ICU to simulate comparable stress situations, as well as to assess the impact of a selective and personalized alarm representation strategy in an evaluation study in two conditions. A stress condition mirrors the current ubiquitous audible alarm distribution in most ICUs, where alarms are heard non-patient-specific throughout the ward. In an experimental condition, alarms are filtered patient-specific to reduce information overload and noise pollution. Our user study with medical personnel and novices shows that stress levels can be simulated with our system as indicated by physiological responses. Further, we show that the perceived task load can be reduced with selective information presentation. We discuss the potential benefits of ICU simulations as a methodology and personalized alarm distribution as a first potential strategy for future technologies in ICUs.
                        </p>
                    </div>
                </div>
            </div>
        </div>
        <br>
        <div class="row">
            <div class="col-lg-4 col-md-4 col-sm-12 text-center">
                <img width="100%" src="assets/img/Tangibles.png">
            </div>
            <div class="col-lg-8 col-md-8 col-sm-12">
                <span class="papertitle">Adaptive Volumetric Anatomy Visualization in VR with Tangible Control</span>

                <br>
                <span style="font-weight: lighter">C. Kleinbeck, M. Smietana, N. Lewis, T. Teufel, </span>J. Kreimeier<span style="font-weight: lighter">, C. Heinzl, J. Steiner, C. Anthes, and D. Roth</span>
                <br>
                <em>International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)</em>, 2023
                <br>
                <p class="d-inline-flex gap-1">
                    <a class="btn btn-dark" data-bs-toggle="collapse" href="#collapseTangibles" role="button" aria-expanded="false" aria-controls="collapseTangibles">
                        Abstract
                    </a>
                    <a class="btn btn-dark" href="https://ieeexplore.ieee.org/abstract/document/10322288">
                        IEEE
                    </a>
                </p>
                <div class="collapse" id="collapseTangibles">
                    <div class="card card-body">
                        <p>
                            High-quality visualization of medical image data is essential for preoperative planning of complex and critical surgical procedures. Controllable 3D volume rendering in virtual reality (VR) is particularly useful to display depth and spatial relationships in volumetric data, and thus to identify specific anatomical landmarks and structural dependencies. However, intuitive control over the medical volume itself, the selection of sectional planes, transfer functions or the rotation or zooming has yet to be explored in depth. In this work, we demonstrate a real-time VR direct volume rendering application for medical images with tangible and intuitive interaction. Our system is real-time capable by the use of efficient volume rendering and foveated rendering techniques. We evaluated the system regarding its performance and gained first insight into the usefulness of a freely grabbable section slice in a preliminary user study.
                        </p>
                    </div>
                </div>
            </div>
        </div>
        <br>
        <div class="row">
            <div class="col-lg-4 col-md-4 col-sm-12 text-center">
                <img width="100%" src="assets/img/ReflectAR.png">
            </div>
            <div class="col-lg-8 col-md-8 col-sm-12">
                <span class="papertitle">Reflect-AR: Insights into Mirror-Based Augmented Reality Instructions to Support Manual Assembly Tasks</span>

                <br>
                <span style="font-weight: lighter">P. Karg, R. Stoehr, L. Jonas, </span>J. Kreimeier<span style="font-weight: lighter">, and T. Goetzelmann </span>
                <br>
                <em> International Conference on PErvasive Technologies Related to Assistive Environments</em>, 2023
                <br>
                <p class="d-inline-flex gap-1">
                    <a class="btn btn-dark" data-bs-toggle="collapse" href="#collapseReflectAR" role="button" aria-expanded="false" aria-controls="collapseReflectAR">
                        Abstract
                    </a>
                    <a class="btn btn-dark" href="https://dl.acm.org/doi/abs/10.1145/3594806.3594866">
                        ACM
                    </a>
                </p>
                <div class="collapse" id="collapseReflectAR">
                    <div class="card card-body">
                        <p>
                            Manual assembly tasks can be difficult and tedious without assistance. Here, augmented reality (AR) can help to ease the task load and lower the time and error rates by interactive in-situ instructions. Such approaches are often implemented by video or optical see-through AR. In order to test a system that is as low-threshold as possible and easy to implement, we developed a prototype with a mirror display supplemented by a RGB-D camera and evaluated it against an well-established AR HMD (HoloLens 2). For this purpose, in our study 10 participants placed 3D printed bricks via both technologies. The quantitative and qualitative analysis revealed that the fulfillment of this task with a professional, established product AR HMD yet remains unmatched in terms of the time required, error rate, usability and task load due to the prototype status and the remaining technical shortcomings. However, the mirror display setup prototype met with interest from the participants as a novel, but unfamiliar and thus more difficult to use way of interaction. Furthermore, we report implementation challenges and advises. The empirical insights of our prototype and the first-time comparison to an established AR HMD aims to foster refining future work with half-silvered AR mirrors as an little researched field and many different fields of application.
                        </p>
                    </div>
                </div>
            </div>
        </div>

    </div>
</section>